{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133481ff",
   "metadata": {},
   "source": [
    "# EEG BCI Competition 2a â€” Simple GNN (GCN) on per-channel features\n",
    "This notebook trains a lightweight **Graph Convolutional Network** without PyTorch Geometric.\n",
    "\n",
    "**Split is identical** to the CNN notebook (and your teammate): `random_state=42`, `test_size=0.2`, `stratify=y`.\n",
    "\n",
    "We build a fixed graph over channels and use **bandpower features** per channel (Welch PSD) as node features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e844d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U numpy pandas scikit-learn torch scipy mne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3db949d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.signal import welch\n",
    "from mne.filter import filter_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39880af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Config (EDIT ME)\n",
    "# =====================\n",
    "DATA_DIR = r\"C:\\Users\\daiva\\Desktop\\Applied-Machine-Learning-Project\\Dataset\\BCI Competition 2a\\Trials\"\n",
    "CSV_GLOB = os.path.join(DATA_DIR, \"A??T_trials.csv\")\n",
    "SUBJECTS = None  # set e.g. [\"A01T\"] to match teammate's single-subject scope\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "SPLIT_SEED = 42\n",
    "USE_STRATIFY = True\n",
    "\n",
    "# Signal params (BCI Competition 2a commonly uses 250 Hz)\n",
    "FS = 250\n",
    "BANDS = [(1,4), (4,8), (8,13), (13,30), (30,40)]  # delta, theta, alpha, beta, gamma\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LR = 1e-3\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd321c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed_trials.npz (2592, 22, 1000)\n",
      "Trials: 2592 Channels: 22 Times: 1000 Classes: 4\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Load preprocessed trials if available; otherwise recreate\n",
    "# =====================\n",
    "def load_trials_from_csv(csv_path: str):\n",
    "    header = pd.read_csv(csv_path, nrows=0)\n",
    "    eeg_cols = [c for c in header.columns if c.startswith('EEG')]\n",
    "    usecols = ['Trial_ID', 'Label', 'Subject'] + eeg_cols\n",
    "    df = pd.read_csv(csv_path, usecols=usecols)\n",
    "\n",
    "    trial_ids = sorted(df['Trial_ID'].unique())\n",
    "    n_times = (df[df['Trial_ID'] == trial_ids[0]].shape[0])\n",
    "    n_channels = len(eeg_cols)\n",
    "\n",
    "    X = np.zeros((len(trial_ids), n_channels, n_times), dtype=np.float32)\n",
    "    y = np.zeros((len(trial_ids),), dtype=np.int64)\n",
    "    trial_keys = []\n",
    "    for i, tid in enumerate(trial_ids):\n",
    "        trial = df[df['Trial_ID'] == tid]\n",
    "        X[i] = trial[eeg_cols].to_numpy(dtype=np.float32).T\n",
    "        y[i] = int(trial['Label'].iloc[0])\n",
    "        subj = str(trial['Subject'].iloc[0])\n",
    "        trial_keys.append(f\"{subj}_{int(tid)}\")\n",
    "    return X, y, trial_keys, eeg_cols\n",
    "\n",
    "if os.path.exists('preprocessed_trials.npz'):\n",
    "    z = np.load('preprocessed_trials.npz', allow_pickle=True)\n",
    "    X = z['X']\n",
    "    y = z['y']\n",
    "    keys = z['keys'].tolist()\n",
    "    eeg_cols = z['eeg_cols'].tolist()\n",
    "    label_values = z['label_values'].tolist()\n",
    "    print('Loaded preprocessed_trials.npz', X.shape)\n",
    "else:\n",
    "    csv_files = sorted(glob.glob(CSV_GLOB))\n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files matched {CSV_GLOB}. Check DATA_DIR.\")\n",
    "    Xs, ys, keys = [], [], []\n",
    "    eeg_cols_ref = None\n",
    "    for p in csv_files:\n",
    "        Xp, yp, kp, eeg_cols_p = load_trials_from_csv(p)\n",
    "        if SUBJECTS is not None:\n",
    "            subj = kp[0].split('_')[0]\n",
    "            if subj not in SUBJECTS:\n",
    "                continue\n",
    "        if eeg_cols_ref is None:\n",
    "            eeg_cols_ref = eeg_cols_p\n",
    "        elif eeg_cols_p != eeg_cols_ref:\n",
    "            raise ValueError(f\"EEG columns mismatch in {p}\")\n",
    "        Xs.append(Xp); ys.append(yp); keys.extend(kp)\n",
    "    X = np.concatenate(Xs, axis=0)\n",
    "    y_raw = np.concatenate(ys, axis=0)\n",
    "    label_values = sorted(np.unique(y_raw).tolist())\n",
    "    label_to_idx = {lab:i for i,lab in enumerate(label_values)}\n",
    "    y = np.array([label_to_idx[int(v)] for v in y_raw], dtype=np.int64)\n",
    "    eeg_cols = eeg_cols_ref\n",
    "    np.savez('preprocessed_trials.npz', X=X, y=y, keys=np.array(keys), eeg_cols=np.array(eeg_cols), label_values=np.array(label_values))\n",
    "    print('Saved preprocessed_trials.npz', X.shape)\n",
    "\n",
    "n_trials, n_channels, n_times = X.shape\n",
    "n_classes = len(np.unique(y))\n",
    "print('Trials:', n_trials, 'Channels:', n_channels, 'Times:', n_times, 'Classes:', n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44493037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= IDENTICAL to randomforestv2 preprocessing =======\n",
    "from mne.filter import filter_data\n",
    "\n",
    "SFREQ = 250.0\n",
    "L_FREQ = 8.0\n",
    "H_FREQ = 30.0\n",
    "\n",
    "# X is (n_trials, n_channels, n_times)\n",
    "X_filt = np.zeros_like(X, dtype=np.float64)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    X_filt[i] = filter_data(\n",
    "        X[i].astype(np.float64),   # <-- THIS is the fix\n",
    "        sfreq=SFREQ,\n",
    "        l_freq=L_FREQ,\n",
    "        h_freq=H_FREQ,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "X = X_filt.astype(np.float32)  # back to float32 for torch\n",
    "print(\"Filtered X:\", X.shape, X.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d6241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded split_indices_seed42.npz\n",
      "Train: 2073 Test: 519\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Split indices (reuse if present)\n",
    "# =====================\n",
    "if os.path.exists('split_indices_seed42.npz'):\n",
    "    z = np.load('split_indices_seed42.npz', allow_pickle=True)\n",
    "    train_idx, test_idx = z['train_idx'], z['test_idx']\n",
    "    print('Loaded split_indices_seed42.npz')\n",
    "else:\n",
    "    idx = np.arange(len(y))\n",
    "    strat = y if USE_STRATIFY else None\n",
    "    train_idx, test_idx = train_test_split(idx, test_size=TEST_SIZE, random_state=SPLIT_SEED, stratify=strat)\n",
    "    np.savez('split_indices_seed42.npz', train_idx=train_idx, test_idx=test_idx, keys=np.array(keys), y=y)\n",
    "    print('Saved split_indices_seed42.npz')\n",
    "\n",
    "print('Train:', len(train_idx), 'Test:', len(test_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46202c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded gnn_node_features_logbandpower.npz (2592, 22, 5)\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Node features: bandpower per channel per trial (Welch PSD)\n",
    "# We'll cache to disk because this can take a few minutes.\n",
    "# =====================\n",
    "def bandpower_features(trial_ch_time: np.ndarray, fs: int, bands):\n",
    "    # trial_ch_time: (C, T)\n",
    "    feats = np.zeros((trial_ch_time.shape[0], len(bands)), dtype=np.float32)\n",
    "    for c in range(trial_ch_time.shape[0]):\n",
    "        f, Pxx = welch(trial_ch_time[c], fs=fs, nperseg=min(256, trial_ch_time.shape[1]))\n",
    "        for bi, (lo, hi) in enumerate(bands):\n",
    "            mask = (f >= lo) & (f < hi)\n",
    "            # integrate PSD over band\n",
    "            feats[c, bi] = np.trapz(Pxx[mask], f[mask]).astype(np.float32)\n",
    "    # log transform to reduce skew\n",
    "    return np.log(feats + 1e-10)\n",
    "\n",
    "feat_cache = 'gnn_node_features_logbandpower.npz'\n",
    "if os.path.exists(feat_cache):\n",
    "    z = np.load(feat_cache)\n",
    "    F = z['F']  # (N, C, B)\n",
    "    print('Loaded', feat_cache, F.shape)\n",
    "else:\n",
    "    F = np.zeros((n_trials, n_channels, len(BANDS)), dtype=np.float32)\n",
    "    for i in range(n_trials):\n",
    "        F[i] = bandpower_features(X[i], FS, BANDS)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Computed {i+1}/{n_trials}')\n",
    "    np.savez(feat_cache, F=F)\n",
    "    print('Saved', feat_cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f85c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency shape: (2592, 22, 22)\n"
     ]
    }
   ],
   "source": [
    "# ===== Build trial-specific adjacency matrices =====\n",
    "\n",
    "# AFTER bandpass, BEFORE corr_adj\n",
    "FS = 250\n",
    "X = X[:, :, int(2*FS):int(6*FS)]\n",
    "\n",
    "\n",
    "def corr_adj(trial, thr=0.3):\n",
    "    \"\"\"\n",
    "    trial: (C, T)\n",
    "    Signed, sparse, normalized adjacency\n",
    "    \"\"\"\n",
    "    A = np.corrcoef(trial)\n",
    "    A = np.nan_to_num(A)\n",
    "\n",
    "    # keep sign (DO NOT abs)\n",
    "    A[np.abs(A) < thr] = 0.0\n",
    "\n",
    "    # self-loops\n",
    "    np.fill_diagonal(A, 1.0)\n",
    "\n",
    "    # normalize by max abs value\n",
    "    maxv = np.max(np.abs(A))\n",
    "    if maxv > 0:\n",
    "        A = A / maxv\n",
    "\n",
    "    return A.astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "A_trials = np.stack([corr_adj(X[i], thr=0.5) for i in range(len(X))])\n",
    "A_train = A_trials[train_idx]\n",
    "A_test  = A_trials[test_idx]\n",
    "print(\"Adjacency shape:\", A_trials.shape)  # (N, C, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized node features.\n"
     ]
    }
   ],
   "source": [
    "# Standardize node features using TRAIN only\n",
    "F_train = F[train_idx]\n",
    "mean = F_train.mean(axis=(0,1), keepdims=True)\n",
    "std = F_train.std(axis=(0,1), keepdims=True) + 1e-8\n",
    "Fn = (F - mean) / std\n",
    "\n",
    "Fn_train = Fn[train_idx]\n",
    "Fn_test  = Fn[test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_test  = y[test_idx]\n",
    "\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = class_counts.sum() / class_counts\n",
    "class_weights = torch.tensor(class_weights, device=DEVICE, dtype=torch.float32)\n",
    "\n",
    "crit = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "print('Standardized node features.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c81ea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency ready: torch.Size([22, 22])\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# Build fixed adjacency over channels\n",
    "# For simplicity we use a fully-connected graph + self loops.\n",
    "# =====================\n",
    "C = n_channels\n",
    "A = np.ones((C, C), dtype=np.float32)\n",
    "np.fill_diagonal(A, 1.0)\n",
    "\n",
    "# Normalize: A_hat = D^{-1/2} A D^{-1/2}\n",
    "D = np.sum(A, axis=1)\n",
    "D_inv_sqrt = np.diag(1.0 / np.sqrt(D + 1e-8))\n",
    "A_hat = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "A_hat = torch.from_numpy(A_hat).to(DEVICE)\n",
    "\n",
    "print('Adjacency ready:', A_hat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, F, A, y):\n",
    "        self.F = torch.from_numpy(F).float()\n",
    "        self.A = torch.from_numpy(A).float()\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.F[i], self.A[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    GraphDataset(Fn_train, A_train, y_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    GraphDataset(Fn_test, A_test, y_test),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigGCN(\n",
      "  (fc_in): Linear(in_features=5, out_features=128, bias=True)\n",
      "  (gcn1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (gcn2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (gcn3): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (1): Softmax(dim=1)\n",
      "  )\n",
      "  (cls): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (act): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BigGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc_in = nn.Linear(in_feats, hidden)\n",
    "\n",
    "        self.gcn1 = nn.Linear(hidden, hidden)\n",
    "        self.gcn2 = nn.Linear(hidden, hidden)\n",
    "        self.gcn3 = nn.Linear(hidden, hidden)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden)\n",
    "        self.norm2 = nn.LayerNorm(hidden)\n",
    "        self.norm3 = nn.LayerNorm(hidden)\n",
    "\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(hidden, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "        self.cls = nn.Linear(hidden, n_classes)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def gcn(self, X, A, layer, norm):\n",
    "        H = layer(X)\n",
    "        H = torch.bmm(A, H)\n",
    "        return self.act(norm(H))\n",
    "\n",
    "    def forward(self, X, A):\n",
    "        # X: (B, C, F), A: (B, C, C)\n",
    "        H = self.fc_in(X)\n",
    "\n",
    "        H1 = self.gcn(H, A, self.gcn1, self.norm1)\n",
    "        H2 = self.gcn(H1 + H, A, self.gcn2, self.norm2)\n",
    "        H3 = self.gcn(H2 + H1, A, self.gcn3, self.norm3)\n",
    "\n",
    "        # attention pooling over nodes\n",
    "        w = self.attn(H3)              # (B, C, 1)\n",
    "        g = (H3 * w).sum(dim=1)        # (B, hidden)\n",
    "\n",
    "        return self.cls(g)\n",
    "\n",
    "\n",
    "model = BigGCN(\n",
    "    in_feats=Fn.shape[-1],\n",
    "    hidden=128,\n",
    "    n_classes=n_classes\n",
    ").to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ec555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss 1.3980 | train acc 0.315 | test acc 0.270\n",
      "Epoch 02 | loss 1.3650 | train acc 0.317 | test acc 0.276\n",
      "Epoch 03 | loss 1.3651 | train acc 0.321 | test acc 0.279\n",
      "Epoch 04 | loss 1.3571 | train acc 0.320 | test acc 0.285\n",
      "Epoch 05 | loss 1.3530 | train acc 0.344 | test acc 0.276\n",
      "Epoch 06 | loss 1.3430 | train acc 0.333 | test acc 0.270\n",
      "Epoch 07 | loss 1.3469 | train acc 0.316 | test acc 0.285\n",
      "Epoch 08 | loss 1.3467 | train acc 0.326 | test acc 0.291\n",
      "Epoch 09 | loss 1.3439 | train acc 0.349 | test acc 0.272\n",
      "Epoch 10 | loss 1.3409 | train acc 0.345 | test acc 0.272\n",
      "Epoch 11 | loss 1.3381 | train acc 0.338 | test acc 0.276\n",
      "Epoch 12 | loss 1.3349 | train acc 0.342 | test acc 0.295\n",
      "Epoch 13 | loss 1.3310 | train acc 0.347 | test acc 0.270\n",
      "Epoch 14 | loss 1.3366 | train acc 0.357 | test acc 0.279\n",
      "Epoch 15 | loss 1.3288 | train acc 0.360 | test acc 0.293\n",
      "Epoch 16 | loss 1.3324 | train acc 0.347 | test acc 0.287\n",
      "Epoch 17 | loss 1.3266 | train acc 0.354 | test acc 0.277\n",
      "Epoch 18 | loss 1.3246 | train acc 0.357 | test acc 0.293\n",
      "Epoch 19 | loss 1.3295 | train acc 0.347 | test acc 0.270\n",
      "Epoch 20 | loss 1.3207 | train acc 0.362 | test acc 0.274\n",
      "Epoch 21 | loss 1.3227 | train acc 0.352 | test acc 0.272\n",
      "Epoch 22 | loss 1.3279 | train acc 0.356 | test acc 0.272\n",
      "Epoch 23 | loss 1.3165 | train acc 0.358 | test acc 0.283\n",
      "Epoch 24 | loss 1.3173 | train acc 0.352 | test acc 0.274\n",
      "Epoch 25 | loss 1.3261 | train acc 0.357 | test acc 0.283\n",
      "Epoch 26 | loss 1.3178 | train acc 0.355 | test acc 0.297\n",
      "Epoch 27 | loss 1.3096 | train acc 0.375 | test acc 0.304\n",
      "Epoch 28 | loss 1.3133 | train acc 0.377 | test acc 0.304\n",
      "Epoch 29 | loss 1.3143 | train acc 0.357 | test acc 0.270\n",
      "Epoch 30 | loss 1.3128 | train acc 0.345 | test acc 0.254\n",
      "\n",
      "=== GNN Test Set Report ===\n",
      "Accuracy: 0.2543352601156069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.15      0.22       130\n",
      "           2       0.18      0.07      0.10       129\n",
      "           3       0.22      0.48      0.31       130\n",
      "           4       0.30      0.31      0.30       130\n",
      "\n",
      "    accuracy                           0.25       519\n",
      "   macro avg       0.27      0.25      0.23       519\n",
      "weighted avg       0.27      0.25      0.23       519\n",
      "\n",
      "Confusion matrix:\n",
      " [[20  9 74 27]\n",
      " [12  9 76 32]\n",
      " [13 19 63 35]\n",
      " [ 6 14 70 40]]\n"
     ]
    }
   ],
   "source": [
    "# ===== Evaluation helper (GNN version) =====\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, Ab, yb in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            Ab = Ab.to(DEVICE)\n",
    "            logits = model(xb, Ab)\n",
    "            pred = logits.argmax(dim=1).cpu().numpy()\n",
    "            ys.append(yb.numpy())\n",
    "            ps.append(pred)\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_pred = np.concatenate(ps)\n",
    "    return y_true, y_pred\n",
    "\n",
    "def drop_edges(A, p=0.2):\n",
    "    # A: (B, C, C)\n",
    "    mask = (torch.rand_like(A) > p).float()\n",
    "    return A * mask\n",
    "\n",
    "# ===== Training loop =====\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for xb, Ab, yb in train_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        Ab = Ab.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "\n",
    "        Ab = drop_edges(Ab, p=0.2)  # TRAIN ONLY\n",
    "        opt.zero_grad()\n",
    "\n",
    "        logits = model(xb, Ab)\n",
    "        loss = crit(logits, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # ----- Evaluate -----\n",
    "    ytr, ptr = evaluate(model, train_loader)\n",
    "    yte, pte = evaluate(model, test_loader)\n",
    "\n",
    "    tr_acc = accuracy_score(ytr, ptr)\n",
    "    te_acc = accuracy_score(yte, pte)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | loss {np.mean(losses):.4f} | \"\n",
    "        f\"train acc {tr_acc:.3f} | test acc {te_acc:.3f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ===== Final evaluation =====\n",
    "y_true, y_pred = evaluate(model, test_loader)\n",
    "\n",
    "print(\"\\n=== GNN Test Set Report ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=[str(v) for v in label_values]))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb94dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved gnn_model_seed42.pt\n"
     ]
    }
   ],
   "source": [
    "# Save model + feature standardization\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'label_values': label_values,\n",
    "    'eeg_cols': eeg_cols,\n",
    "    'bands': BANDS,\n",
    "    'fs': FS,\n",
    "    'feat_mean': mean.astype(np.float32),\n",
    "    'feat_std': std.astype(np.float32),\n",
    "}, 'gnn_model_seed42.pt')\n",
    "print('Saved gnn_model_seed42.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d735a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged results to experiment_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>model_type</th>\n",
       "      <th>subject</th>\n",
       "      <th>seed</th>\n",
       "      <th>fs</th>\n",
       "      <th>bandpass</th>\n",
       "      <th>zscore</th>\n",
       "      <th>time_window</th>\n",
       "      <th>n_trials_train</th>\n",
       "      <th>n_trials_test</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-17T15:16:52</td>\n",
       "      <td>GNN</td>\n",
       "      <td>A01T</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>8-30</td>\n",
       "      <td>True</td>\n",
       "      <td>full</td>\n",
       "      <td>2073</td>\n",
       "      <td>519</td>\n",
       "      <td>0.254335</td>\n",
       "      <td>0.232277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp model_type subject  seed   fs bandpass  zscore  \\\n",
       "0  2025-12-17T15:16:52        GNN    A01T    42  250     8-30    True   \n",
       "\n",
       "  time_window  n_trials_train  n_trials_test  test_accuracy  macro_f1  \n",
       "0        full            2073            519       0.254335  0.232277  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ===== CONFIG =====\n",
    "RESULTS_CSV = \"experiment_results.csv\"\n",
    "MODEL_TYPE = \"GNN\"   # change to \"GNN\" in the GNN notebook\n",
    "SUBJECT = \"A02T\"     # update dynamically if looping subjects\n",
    "SEED = 42\n",
    "FS = 250\n",
    "BANDPASS = \"8-30\"\n",
    "ZSCORE = True        # False if you disable it\n",
    "TIME_WINDOW = \"full\" # or \"2-6s\"\n",
    "\n",
    "# ===== METRICS =====\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "row = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"model_type\": MODEL_TYPE,\n",
    "    \"subject\": SUBJECT,\n",
    "    \"seed\": SEED,\n",
    "    \"fs\": FS,\n",
    "    \"bandpass\": BANDPASS,\n",
    "    \"zscore\": ZSCORE,\n",
    "    \"time_window\": TIME_WINDOW,\n",
    "    \"n_trials_train\": len(train_idx),\n",
    "    \"n_trials_test\": len(test_idx),\n",
    "    \"test_accuracy\": test_acc,\n",
    "    \"macro_f1\": macro_f1,\n",
    "}\n",
    "\n",
    "df_row = pd.DataFrame([row])\n",
    "\n",
    "# ===== APPEND OR CREATE =====\n",
    "if os.path.exists(RESULTS_CSV):\n",
    "    df_row.to_csv(RESULTS_CSV, mode=\"a\", header=False, index=False)\n",
    "else:\n",
    "    df_row.to_csv(RESULTS_CSV, index=False)\n",
    "\n",
    "print(\"Logged results to\", RESULTS_CSV)\n",
    "df_row\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "title": "EEG GNN (BCI 2a)"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
