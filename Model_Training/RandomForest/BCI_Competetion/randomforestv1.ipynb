{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761bdf1d",
   "metadata": {},
   "source": [
    "\n",
    "This is for the BCI Competetion 2a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d81ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527a1f94",
   "metadata": {},
   "source": [
    "There are 4 Bands of data (frequencies) we are looking for [Theta, Alpha, Beta, Gamma] \n",
    "\n",
    "Theta     4-8 Hz    Drowsiness/cognitive load\n",
    "Alpha     8-13 Hz   suppressed when you imagine moving \n",
    "Beta      13-30 Hz  motor imagenry/brain planning\n",
    "Gamma     30-45 Hz  cognitive/motor activity signals\n",
    "\n",
    "It is important to note that the subject is imagining moving, not actually moving \n",
    "so we expect Alpha and Beta to change, thus should be our main focus \n",
    "\n",
    "We are using Welch method to estimate the power spectral density (PSD), basically how much power the eeg has at each one of those frequencies\n",
    "\n",
    "Welch Method:\n",
    "1. Break signal into overlapping windows\n",
    "2. Compute frequency transform for each window\n",
    "3. Average them to get a power estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1142232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpower(data, sf=250):\n",
    "    # freqs is the array of frq from 0-125 Hz (we are interested in 0-45 Hz)\n",
    "    # psd is the PSD of the data\n",
    "    freqs, psd = welch(data, sf, nperseg=250)  # 250 is the sampling frequncy of the data (stated in the pdf)\n",
    "\n",
    "    # This is to calcualte the AUC of the PSD curve between fmin and fmax\n",
    "    def bp(fmin, fmax):\n",
    "        idx = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
    "        return np.trapz(psd[idx], freqs[idx])   # This is the total power in the band\n",
    "\n",
    "    # Now it returns the power in each of the bands\n",
    "    return {\n",
    "        \"theta\": bp(4, 8),\n",
    "        \"alpha\": bp(8, 13),\n",
    "        \"beta\":  bp(13, 30),\n",
    "        \"gamma\": bp(30, 45)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eefec68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(\"C:/Users/ahmad/OneDrive/General/Obsidian2/Classes/Fall 2025/EE595_AppliedMachineLearning/Project/Applied-Machine-Learning-Project/Dataset/BCI Competition 2a/Trials/A01T_trials.csv\")  \n",
    "# Get unique trials\n",
    "trial_ids = df[\"Trial_ID\"].unique()\n",
    "\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66bbe8e",
   "metadata": {},
   "source": [
    "There are 22 channles and we are extracting 4 bands from each so \n",
    "22 * 4 = 88 features\n",
    "\n",
    "In addition, the main benefit of choosing this dataset over our initial dataset, is that we get access to the unsummarized data\n",
    "\n",
    "My hypothesis for why the model performed poorly to our old data, wasn't just because of the small set, but because the Random Forest wasn't able to draw noticable patterns from it. I had plotted the data to try to extract patterns myself to guide the model more, although it made a difference it wasn't substantial enough to rely on.\n",
    "\n",
    "With this dataset we have an extra factor of data, time series, which will show the change in a persons thoughts which we can hopefully exploit \n",
    "\n",
    "So to make use of time series, we will be extracting this data:\n",
    "1. Mean       [Average]\n",
    "2. Variance   [Flucatuation]\n",
    "3. Skew       [Waveform leaning up or down?]\n",
    "4. Kurtosis   [If the signal has sharp peaks or flat peaks]\n",
    "5. Root Mean Square [Strength of signal]\n",
    "\n",
    "\n",
    "So now we have 5 additional feature categories:\n",
    "22 * 5 = 110\n",
    "\n",
    "110 + 88 = 198 total features for the model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac52521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmad\\AppData\\Local\\Temp\\ipykernel_25672\\1214607144.py:9: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return np.trapz(psd[idx], freqs[idx])   # This is the total power in the band\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "\n",
    "# Loop over every row with the same trial id\n",
    "for tid in trial_ids:\n",
    "\n",
    "    trial_df = df[df[\"Trial_ID\"] == tid]\n",
    "    label = trial_df[\"Label\"].iloc[0]\n",
    "    labels.append(label)\n",
    "    trial_features = {}\n",
    "\n",
    "    # Exclude Time, Label, Trial_ID, Subject\n",
    "    channels = [c for c in trial_df.columns if c.startswith(\"EEG\")]\n",
    "\n",
    "    # Loop over every channel\n",
    "    for ch in channels:\n",
    "        x = trial_df[ch].values\n",
    "\n",
    "        # Calculate bps for each channel\n",
    "        bp = bandpower(x)\n",
    "        for key, val in bp.items():\n",
    "            trial_features[f\"{ch}_{key}\"] = val\n",
    "        \n",
    "        # Time Based features\n",
    "        trial_features[f\"{ch}_mean\"] = np.mean(x)\n",
    "        trial_features[f\"{ch}_var\"]  = np.var(x)\n",
    "        trial_features[f\"{ch}_skew\"] = pd.Series(x).skew()\n",
    "        trial_features[f\"{ch}_kurt\"] = pd.Series(x).kurt()\n",
    "\n",
    "    features.append(trial_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4cc7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "X = pd.DataFrame(features)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7b3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN / TEST SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b63ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# 3 Fold Cross Validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=param_grid, \n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    verbose=2,\n",
    "    scoring='accuracy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c0960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "\n",
      "Best Parameters found: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Cross-Validation Score: 0.5174868990658464\n",
      "\n",
      "--- Test Set Results (Best Model) ---\n",
      "Accuracy: 0.39655172413793105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.27      0.29        15\n",
      "           2       0.47      0.57      0.52        14\n",
      "           3       0.17      0.13      0.15        15\n",
      "           4       0.56      0.64      0.60        14\n",
      "\n",
      "    accuracy                           0.40        58\n",
      "   macro avg       0.38      0.40      0.39        58\n",
      "weighted avg       0.37      0.40      0.38        58\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Starting Grid Search...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters found:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Test Set Results (Best Model) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9f2f7e",
   "metadata": {},
   "source": [
    "Starting Grid Search...\n",
    "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
    "\n",
    "Best Parameters found: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "Best Cross-Validation Score: 0.5174868990658464\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.39655172413793105\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.31      0.27      0.29        15\n",
    "           2       0.47      0.57      0.52        14\n",
    "           3       0.17      0.13      0.15        15\n",
    "           4       0.56      0.64      0.60        14"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
