{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3003fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mne.filter import filter_data\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f8f50a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "TRIALS_CSV = \"C:/Users/ahmad/OneDrive/General/Obsidian2/Classes/Fall 2025/EE595_AppliedMachineLearning/Project/Applied-Machine-Learning-Project/Dataset/BCI Competition 2a/Trials/A09T_trials.csv\"   # change to your path\n",
    "SFREQ = 250.0                    # Hz sampling rate from pdf\n",
    "\n",
    "# We are going to try focusing on only the bands we expect to change (this was mentioned in detail in V1, but I never changed it to emphasize those bands)\n",
    "L_FREQ = 8.0                     \n",
    "H_FREQ = 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4817a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 22 EEG channels: ['EEG-Fz', 'EEG-0', 'EEG-1', 'EEG-2', 'EEG-3', 'EEG-4', 'EEG-5', 'EEG-C3', 'EEG-6', 'EEG-Cz', 'EEG-7', 'EEG-C4', 'EEG-8', 'EEG-9', 'EEG-10', 'EEG-11', 'EEG-12', 'EEG-13', 'EEG-14', 'EEG-Pz', 'EEG-15', 'EEG-16']\n",
      "288 trials, 22 channels, 1000 time points per trial\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv(TRIALS_CSV)\n",
    "\n",
    "# Restrict to one subject (Each csv has only one subject, but in the future I might concatenate all the CSVs together)\n",
    "subject_id = \"A09T\"\n",
    "df = df[df[\"Subject\"] == subject_id]\n",
    "\n",
    "\n",
    "# Exclude Time, EOG, Label, basically everything else whose columns name doesn't start with EEG\n",
    "eeg_cols = [c for c in df.columns if c.startswith(\"EEG\")]\n",
    "print(f\"Using {len(eeg_cols)} EEG channels:\", eeg_cols)\n",
    "\n",
    "\n",
    "# Get trial IDs and number of samples per trial\n",
    "trial_ids = sorted(df[\"Trial_ID\"].unique())\n",
    "n_trials = len(trial_ids)\n",
    "n_channels = len(eeg_cols)\n",
    "\n",
    "\n",
    "# Im assuming all the trials have the same length\n",
    "# For the AO1T it doees add up in the file there are 288001 rows (+1 rows cause of header) \n",
    "n_times = df[df[\"Trial_ID\"] == trial_ids[0]].shape[0]\n",
    "print(f\"{n_trials} trials, {n_channels} channels, {n_times} time points per trial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a151b11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c9f0e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (288, 22, 1000)\n",
      "y shape: (288,) classes: [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# We are creating a 3D matrix (n_trials x n_channels x n_times)\n",
    "X = np.zeros((n_trials, n_channels, n_times), dtype=np.float64)\n",
    "y = np.zeros(n_trials, dtype=int)\n",
    "\n",
    "'''\n",
    "For each trial, grab all rows with the same trial_id, taking only the EEG columns (n_times x n_channels)\n",
    "Then transpose it to (n_channels x n_times) to be used in CSP (its how it expects it)\n",
    "save it in X[i] and save the label in y[i]\n",
    "'''\n",
    "for i, tid in enumerate(trial_ids):\n",
    "    trial = df[df[\"Trial_ID\"] == tid]\n",
    "    X[i] = trial[eeg_cols].to_numpy().T\n",
    "    # same label for entire trial\n",
    "    y[i] = int(trial[\"Label\"].iloc[0])\n",
    "\n",
    "\n",
    "print(\"X shape:\", X.shape) # (n_trials, n_channels, n_times)\n",
    "print(\"y shape:\", y.shape, \"classes:\", np.unique(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c67c7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want CSP to focus on the 8-30 Hz band, so remove the rest of the unneeded frequencies\n",
    "for i in range(n_trials):\n",
    "    X[i] = filter_data(X[i], sfreq=SFREQ, l_freq=L_FREQ, h_freq=H_FREQ, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6bfd559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try not using straisfy and split by trail instead\n",
    "\n",
    "# We could use stratify with the previous dataset, because each row was essentialy a trial, but now with the time\n",
    "# series data, we shouldn't use startisft but save entire sets of trials for each label, because we would be losing parts of the information for a trial\n",
    "# which would decrease training accuracy (as its missing data it needs) and testing accuracy (it sees new data that its not familiar with or have an idea how it could possibly fit)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d5c21",
   "metadata": {},
   "source": [
    "When analyzing the distribution of the data of our original csv, I noticed that there was an underlying pattern, where the values of the eeg signals in all channeles for different targets, almost never overlapped, and it was very visibily the case across subjects (I only verified with 3 subjects)\n",
    "\n",
    "So because of this, I hypothesized that although the signals vary person to person, a similiar pattern must exist for all people, which it did (verification of other subjects). This is why I instead brought my attention to dimensionality of the data (time-series) and decided to change the dataset. \n",
    "\n",
    "The original dataset, clearly showed a pattern, however I believed the lack of dimensioanltiy in the data, did not allow Random Forest to effecitvely uncover underlying patterns, or complex ones. At which point I attempted to use factors such as mean, variance, etc... to guide it to creating more distinctions. \n",
    "\n",
    "It did improve the model a bit, from \n",
    "0.2-0.33 over EEG Neuroprosthetic Dataset (about 5% better than guessing)\n",
    "to\n",
    "0.4 over the BCI_2a Dataset\n",
    "so there was an improvement (Note that these are over two different datasets, however they contained the same channels, one just lacks time-series data (but has optimized channels) while the new one has raw time series data)\n",
    "\n",
    "\n",
    "Now with the time-series data, we look at it as a matrix (channel x time)\n",
    "using the MNE library, we use the CSP function (Common Spatial Patterns) that does a one vs rest protocol and assigns weights to them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "83b24ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSP FEATURE EXTRACTION\n",
    "\n",
    "# n_components = number of CSP filters (per class one-vs-rest)\n",
    "# TODO: Use grid search to find the best n_components\n",
    "csp = CSP(\n",
    "    n_components=8,\n",
    "    reg='ledoit_wolf',\n",
    "    log=True,\n",
    "    # If you get an error here, you might need to downgrade or upgrade your mne library (I have it at 1.11.0)\n",
    "    # You can keep your current version, but check the documentation for the right keyword\n",
    "    transform_into='average_power'   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33ab5389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using tolerance 9e-05 (2.2e-16 eps * 22 dim * 1.8e+10  max singular value)\n",
      "    Estimated rank (data): 22\n",
      "    data: rank 22 computed from 22 data channels with 0 projectors\n",
      "Reducing data rank from 22 -> 22\n",
      "Estimating class=1 covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Estimating class=2 covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Estimating class=3 covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "Estimating class=4 covariance using LEDOIT_WOLF\n",
      "Done.\n",
      "CSP features shape (train): (230, 8)\n",
      "CSP features shape (test): (58, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train_csp = csp.fit_transform(X_train, y_train)\n",
    "X_test_csp = csp.transform(X_test)\n",
    "\n",
    "print(\"CSP features shape (train):\", X_train_csp.shape)\n",
    "print(\"CSP features shape (test):\", X_test_csp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "678138c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ab04e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest on CSP features\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf, \n",
    "    param_grid=param_grid, \n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    verbose=2,\n",
    "    scoring='accuracy'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fec5036e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search...\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "/nBest Parameters found: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Cross-Validation Score: 0.6869446343130554\n",
      "\n",
      "--- Test Set Results (Best Model) ---\n",
      "Accuracy: 0.5862068965517241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.87      0.68        15\n",
      "           2       0.60      0.43      0.50        14\n",
      "           3       0.50      0.33      0.40        15\n",
      "           4       0.67      0.71      0.69        14\n",
      "\n",
      "    accuracy                           0.59        58\n",
      "   macro avg       0.58      0.59      0.57        58\n",
      "weighted avg       0.58      0.59      0.57        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Grid Search...\")\n",
    "grid_search.fit(X_train_csp, y_train)\n",
    "\n",
    "# Get Best Parameters and Model\n",
    "print(\"/nBest Parameters found:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict and Evaluate using the Best Model on CSP test features\n",
    "y_pred = best_rf.predict(X_test_csp)\n",
    "\n",
    "print(\"\\n--- Test Set Results (Best Model) ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "beba88bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfinal_model = Pipeline([\\n    (\\'csp\\', csp),        # The spatial filter\\n    (\\'clf\\', best_rf)     # The best random forest from grid search\\n])\\n\\nsave_path = \"C:/Users/ahmad/OneDrive/General/Obsidian2/Classes/Fall 2025/EE595_AppliedMachineLearning/Project/Applied-Machine-Learning-Project/Model_Training/RandomForest/BCI_Competetion/models/csp_rf_model_v2.joblib\"\\n\\nimport os\\nos.makedirs(os.path.dirname(save_path), exist_ok=True)\\n\\njoblib.dump(final_model, save_path)\\n\\nprint(f\"Pipeline successfully saved\")\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "'''\n",
    "final_model = Pipeline([\n",
    "    ('csp', csp),        # The spatial filter\n",
    "    ('clf', best_rf)     # The best random forest from grid search\n",
    "])\n",
    "\n",
    "save_path = \"C:/Users/ahmad/OneDrive/General/Obsidian2/Classes/Fall 2025/EE595_AppliedMachineLearning/Project/Applied-Machine-Learning-Project/Model_Training/RandomForest/BCI_Competetion/models/csp_rf_model_v2.joblib\"\n",
    "\n",
    "import os\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "joblib.dump(final_model, save_path)\n",
    "\n",
    "print(f\"Pipeline successfully saved\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82650fb5",
   "metadata": {},
   "source": [
    "Trial 1:\n",
    "Best Cross-Validation Score: 0.7390635680109364\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.7413793103448276\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.82      0.60      0.69        15\n",
    "           2       0.67      0.86      0.75        14\n",
    "           3       0.73      0.73      0.73        15\n",
    "           4       0.79      0.79      0.79        14\n",
    "\n",
    "    accuracy                           0.74        58\n",
    "   macro avg       0.75      0.74      0.74        58\n",
    "weighted avg       0.75      0.74      0.74        58\n",
    "\n",
    "\n",
    "Trial 2:\n",
    "Best Cross-Validation Score: 0.6520277967646388\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.603448275862069\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.47      0.47      0.47        15\n",
    "           2       0.43      0.21      0.29        14\n",
    "           3       0.75      1.00      0.86        15\n",
    "           4       0.62      0.71      0.67        14\n",
    "\n",
    "    accuracy                           0.60        58\n",
    "   macro avg       0.57      0.60      0.57        58\n",
    "weighted avg       0.57      0.60      0.57        58\n",
    "\n",
    "Trial 3:\n",
    "Best Cross-Validation Score: 0.8218842560947824\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.8103448275862069\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.92      0.80      0.86        15\n",
    "           2       1.00      0.93      0.96        14\n",
    "           3       0.90      0.60      0.72        15\n",
    "           4       0.59      0.93      0.72        14\n",
    "\n",
    "    accuracy                           0.81        58\n",
    "   macro avg       0.85      0.81      0.82        58\n",
    "weighted avg       0.86      0.81      0.81        58\n",
    "\n",
    "Trial 4:\n",
    "Best Cross-Validation Score: 0.5303599908863066\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.5862068965517241\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.57      0.53      0.55        15\n",
    "           2       0.50      0.50      0.50        14\n",
    "           3       0.69      0.60      0.64        15\n",
    "           4       0.59      0.71      0.65        14\n",
    "\n",
    "    accuracy                           0.59        58\n",
    "   macro avg       0.59      0.59      0.58        58\n",
    "weighted avg       0.59      0.59      0.59        58\n",
    "\n",
    "Trial 5:\n",
    "Best Cross-Validation Score: 0.45659603554340394\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.3275862068965517\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.55      0.40      0.46        15\n",
    "           2       0.30      0.21      0.25        14\n",
    "           3       0.24      0.33      0.28        15\n",
    "           4       0.31      0.36      0.33        14\n",
    "\n",
    "    accuracy                           0.33        58\n",
    "   macro avg       0.35      0.33      0.33        58\n",
    "weighted avg       0.35      0.33      0.33        58\n",
    "\n",
    "Trial 6:\n",
    "Best Cross-Validation Score: 0.504272043745728\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.5172413793103449\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.55      0.73      0.63        15\n",
    "           2       0.43      0.21      0.29        14\n",
    "           3       0.60      0.60      0.60        15\n",
    "           4       0.44      0.50      0.47        14\n",
    "\n",
    "    accuracy                           0.52        58\n",
    "   macro avg       0.50      0.51      0.50        58\n",
    "weighted avg       0.51      0.52      0.50        58\n",
    "\n",
    "Trial 7:\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.7413793103448276\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.67      0.67      0.67        15\n",
    "           2       0.67      0.57      0.62        14\n",
    "           3       0.85      0.73      0.79        15\n",
    "           4       0.78      1.00      0.88        14\n",
    "\n",
    "    accuracy                           0.74        58\n",
    "   macro avg       0.74      0.74      0.74        58\n",
    "weighted avg       0.74      0.74      0.74        58\n",
    "\n",
    "Trial 8:\n",
    "Best Cross-Validation Score: 0.799954431533379\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.7413793103448276\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.75      0.60      0.67        15\n",
    "           2       0.77      0.71      0.74        14\n",
    "           3       0.77      0.67      0.71        15\n",
    "           4       0.70      1.00      0.82        14\n",
    "\n",
    "    accuracy                           0.74        58\n",
    "   macro avg       0.75      0.75      0.74        58\n",
    "weighted avg       0.75      0.74      0.73        58\n",
    "\n",
    "Trial 9:\n",
    "Best Cross-Validation Score: 0.6869446343130554\n",
    "\n",
    "--- Test Set Results (Best Model) ---\n",
    "Accuracy: 0.5862068965517241\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.57      0.87      0.68        15\n",
    "           2       0.60      0.43      0.50        14\n",
    "           3       0.50      0.33      0.40        15\n",
    "           4       0.67      0.71      0.69        14\n",
    "\n",
    "    accuracy                           0.59        58\n",
    "   macro avg       0.58      0.59      0.57        58\n",
    "weighted avg       0.58      0.59      0.57        58\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b33c3b6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
